{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99cca57-f149-4881-8991-55f5229d3c6a",
   "metadata": {},
   "source": [
    "# Group 41 STAT-301 Project Proposal: Predicting Metacritic Score of Steam Games\n",
    "### Introduction\n",
    "\n",
    "Steam is the largest digital distribution platform for computer games. The platform can be seen as a digital community market. It allows its users to purchase games, adding them to a virtual library from which they may be downloaded and installed an unlimited number of times. Metacritic scores rate the overall performance of video games ranging from 0-100, with higher scores indicating more positive reviews, and lower scores indicating less favorable reviews from critics. These scores are helpful since there are thousands of different types of video games published on Steam and consumers may find it difficult to make decisions. There is also research showing that Metacritic scores at least partially explain player experience (Johnson et al., 2014). Therefore, a game's Metacritic score may help consumers make a decision about their game purchasing. And since Metacritic scores have a strong correlation with game sales (Greenwood-Ericksen et al., 2013), understanding and predicting them is important for sellers as well.\n",
    "\n",
    " In our project, we will predict the Metacritic score of Steam games (the response variable) released after the year 1970, based on input variables such as the price, the number of recommendations, and release date of a game. The project will be focused on both prediction and inference. Although our main goal is to predict the game's Metacritic Score, it will be also interesting to find out the different relationships between a game's Metacritic score and its input variables (i.e. which variables explain the variation in Metacritic score the best). \n",
    " \n",
    " \n",
    " The dataset we used is collected and released under the Steam API (Steam Games, 2022). It has the following 19 variables:\n",
    "- 'ResponseName'\n",
    "- 'ReleaseDate'\n",
    "- 'Metacritic'\n",
    "- 'RecommendationCount'\n",
    "- 'IsFree'\n",
    "- 'GenreIsNonGame'\n",
    "- 'GenreIsIndie'\n",
    "- 'GenreIsAction'\n",
    "- 'GenreIsAdventure'\n",
    "- 'GenreIsCasual'\n",
    "- 'GenreIsStrategy'\n",
    "- 'GenreIsRPG'\n",
    "- 'GenreIsSimulation'\n",
    "- 'GenreIsEarlyAccess'\n",
    "- 'GenreIsFreeToPlay'\n",
    "- 'GenreIsSports'\n",
    "- 'GenreIsRacing'\n",
    "- 'GenreIsMassivelyMultiplayer'\n",
    "- 'PriceInitial'\n",
    "\n",
    "The variable `ResponseName` will not be used as it is a unique value representing the name of a game. The continuous input variables in this dataset are `ReleaseDate` (representing the number of days passed since January 1st, 1970), `PriceInitial` (the price of a video game), and `RecommendationCount` (the number of recommendations of a game on Steam). The other variables are logicals (i.e. TRUE  or FALSE) that say whether or not a game fits into a certain genre or category. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd768bf0-76ea-4e1b-9652-691a836b017a",
   "metadata": {},
   "source": [
    "### Preliminary Results\n",
    "In this section, we will demonstrate that we can read the data from the web and wrangle it into a tidy format. We will also address our primary question with plots and tables.\n",
    "#### Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6cb28c-3a78-4922-8130-29266ef221bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(gridExtra): there is no package called ‘gridExtra’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(gridExtra): there is no package called ‘gridExtra’\nTraceback:\n",
      "1. library(gridExtra)"
     ]
    }
   ],
   "source": [
    "# load libraries + set options\n",
    "\n",
    "options(jupyter.plot_mimetypes=\"image/png\")\n",
    "\n",
    "library(repr)\n",
    "library(digest)\n",
    "library(gridExtra)\n",
    "library(faraway)\n",
    "library(mltools)\n",
    "library(leaps)\n",
    "library(tidyverse)\n",
    "library(broom)\n",
    "library(glmnet)\n",
    "library(repr)\n",
    "library(car)\n",
    "library(GGally)\n",
    "\n",
    "\n",
    "\n",
    "options(jupyter.plot_mimetypes = \"image/png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb49bd-75c7-4852-b6a8-833c23a82b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_csv on a url, which responds with the data\n",
    "steam_games <- read_csv('https://raw.githubusercontent.com/DanielZCode/STAT-301-Project/main/games-features-edit.csv')\n",
    "                                                                                           \n",
    "head(steam_games) # preview of the data \n",
    "nrow(steam_games) # 12624 data points (games)\n",
    "colnames(steam_games) #variable names, number of variables == 19\n",
    "#length(colnames(steam_games)) #prints out number of variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d9606f-ec40-487e-a4e9-360610cc78fe",
   "metadata": {},
   "source": [
    "#### Data Wrangling \n",
    "In order to correctly use the `ReleaseDate` variable, we will need to convert it from its current character-based format to a numerical value. Although it would be convenient to convert this variable year that the game was released, that would not be a true continuous variable since years are mostly discrete (especially in the case of Steam games, where the data available is fairly recent). Hence, we will need to convert `ReleaseDate` to a continuous variable representing the number of days passed since January 1st, 1970. This is a common representation of time in computers. \n",
    "\n",
    "In addition, we will filter the data for missing values, and also check that a game's `Metacritic` score is not 0, because that indicates a lack of reviews and an unplayed game. By safely removing those outliers and missing values, we can generate the more accurate model. We will also filter only for games that were released after 1970.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9e974-7e40-45b7-9306-43c49bb2cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(is.na(steam_games)) # dataset has 86 missing data points\n",
    "sum(is.na(steam_games$ReleaseDate)) #all missing data is inside the ReleaseDate \n",
    "\n",
    "set.seed(3012)\n",
    "\n",
    "#convert dates to days since 1970 (default internal representation) \n",
    "steam_games$ReleaseDate <- steam_games$ReleaseDate %>% as.Date(format=\"%b%d%Y\") %>%  as.numeric() \n",
    "\n",
    "\n",
    "steam_games <- steam_games %>% drop_na() %>% filter(Metacritic > 0, ReleaseDate > 0) # filter for more than 0 days passed since 1970, metacritic score > 0\n",
    "\n",
    "steam_games <- steam_games %>% mutate_if(is.logical, as_factor) #convert logicals to factors\n",
    "\n",
    "\n",
    "\n",
    "length(unique(steam_games$GenreIsNonGame)) # == 1, hence only one value for this variable is present, no variation\n",
    "\n",
    "steam_games <- steam_games %>% select(-GenreIsNonGame,-GenreIsFreeToPlay) # remove variables\n",
    "\n",
    "head(steam_games)\n",
    "nrow(steam_games) ## number of steam games, filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2415a6-a205-4a69-8382-4dec0272aa53",
   "metadata": {},
   "source": [
    "After wrangling the data in this way, we are left with 2241 observations, down from the original 12624 observations.\n",
    "\n",
    "In this dataset, it turns out that the `GenreIsNonGame` variable is always false. Because this variable has no variation, it will be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29dff0-2fbb-4007-aaf7-b911b527038b",
   "metadata": {},
   "source": [
    "The binary variable `IsFree` is equivalent to the the binary variable `GenreIsFreeToPlay`. Therefore, the GenreIsFreeToPlay will be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f07e022-2820-4439-a8a7-faf7cc9e50e6",
   "metadata": {},
   "source": [
    "#### Exploratory Analysis\n",
    "In this section we will explore some estimates variables. In addition we will plot visualizations of our reponse variable, `Metacritic`, and its relation to other variables.\n",
    "\n",
    "First, let us see the distribution of `Metacritic` scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c53087-0fbb-42ee-aec5-31994391cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 7, repr.plot.height = 5)\n",
    "\n",
    "steam_games_metacritic_dist <- steam_games %>% ggplot() +\n",
    "    geom_histogram(aes(x = Metacritic), bins = 35, color = '#FF00FF') +\n",
    "    ggtitle('Figure 1: Distribution of Metacritic Scores') +\n",
    "    labs(x = 'Metacritic Score', y = 'Count')\n",
    "\n",
    "steam_games_metacritic_dist\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9a9e95-4ab7-4ac3-8319-ecd0cd36217d",
   "metadata": {},
   "source": [
    "Next, let us plot the relationship of Metacritic Score with the other continous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ddf056-bb93-4846-ace7-6daa5bfc2e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games_metacritic_releasedate_plot <- steam_games %>% ggplot() +\n",
    "    geom_point(aes(x = ReleaseDate, y = Metacritic), size = 0.8, alpha = 0.7) +\n",
    "    geom_smooth(aes(x = ReleaseDate, y = Metacritic), method = lm, se = FALSE, size = 1.5) +\n",
    "    ggtitle('Figure 2: Relationship Between Metacritic Score and Release Date of a Game') +\n",
    "    labs(y = 'Metacritic Score', x = 'Release Date (Number of Days passed since 1970)')\n",
    "steam_games_metacritic_releasedate_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dacb25-ec74-4841-8459-e22c08cd60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games_metacritic_price_plot <- steam_games %>% ggplot() +\n",
    "    geom_point(aes(x = PriceInitial, y = Metacritic),  size = 0.8, alpha = 0.7) +\n",
    "    geom_smooth(aes(x = PriceInitial, y = Metacritic), method = lm, se = FALSE, size = 1.5) +\n",
    "    ggtitle('Figure 3: Relationship Between Price of a Game and Metacritic Score') +\n",
    "    labs(y = 'Metacritic Score', x = 'Price of a Game on Steam ($USD)')\n",
    "steam_games_metacritic_price_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a96b3c-f9a9-4292-8ac6-9d6c281bfcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games_metacritic_recommendation_plot <- steam_games %>% ggplot() +\n",
    "    geom_point(aes(x = RecommendationCount, y = Metacritic),  size = 0.8, alpha = 0.7) +\n",
    "    geom_smooth(aes(x = RecommendationCount, y = Metacritic), method = lm, se = FALSE, size = 1.5) +\n",
    "    scale_x_continuous(limits = c(0, 10000)) +\n",
    "    ggtitle('Figure 4: Relationship Between Recommendation Count and Metacritic Score') +\n",
    "    labs(y = 'Metacritic Score', x = 'Recommendation Count (Number of Recommendations Received on Steam)')\n",
    "steam_games_metacritic_recommendation_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e166aa-fe9d-4507-b713-b66395115721",
   "metadata": {},
   "source": [
    "**Note:** About 180 data points were removed in **Figure 4** for increased clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0c4d0-e985-4c49-938b-1eef5ea8e170",
   "metadata": {},
   "source": [
    "\n",
    "#### Estimates\n",
    "Below we will compute some estimates of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb32c69-a9f8-4a54-b2ad-a699c265d16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games_summarized <- steam_games %>% summarize(Metacritic_mean = mean(Metacritic),\n",
    "                                                    Metacritic_sd = sd(Metacritic),\n",
    "                                                    ReleaseDate_mean = mean(ReleaseDate), \n",
    "                                                    ReleaseDate_mean_Date = format(as.Date(ReleaseDate_mean, origin ='1970-01-01'), '%B %d, %Y'),\n",
    "                                                    RecommendationCount_mean = mean(RecommendationCount),\n",
    "                                                    PriceInitial_mean = mean(PriceInitial))\n",
    "steam_games_summarized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c6072-507d-4e9d-b10a-8ae21618bc26",
   "metadata": {},
   "source": [
    "**Figure 5. Averages of different variables**\n",
    "\n",
    "As we can see, the average Metacritic score of a Steam game is approximately **72**, and the average release date was in **November, 2012**. In addition, Steam games have received around **4600** recommendations on average, and have a mean price of approximately **$15**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a8a1e-a37d-48f8-8ece-84b38dceda15",
   "metadata": {},
   "source": [
    "### Methods and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f4f7c5-4c0c-4a0b-bef9-795d20f58120",
   "metadata": {},
   "source": [
    "First, we should split the data into a training and testing set, where the training set is 60% of the entire data. This is done in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c0815-db54-4d47-a880-833d3c688c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3012)\n",
    "steam_games$ID = 1:nrow(steam_games)\n",
    "training_Steam <- sample_n(steam_games, size = nrow(steam_games) * 0.60,\n",
    "  replace = FALSE\n",
    ")\n",
    "\n",
    "testing_Steam <- anti_join(steam_games,\n",
    "  training_Steam,\n",
    "  by = \"ID\"\n",
    ")\n",
    "\n",
    "# Remove Game ID\n",
    "training_Steam <- training_Steam %>% select(-\"ID\")\n",
    "testing_Steam <- testing_Steam %>% select(-\"ID\")\n",
    "head(training_Steam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e61ffa-19fb-4328-a670-27b1184ada15",
   "metadata": {},
   "source": [
    "#### Preliminary Model\n",
    "Before selecting the varubales, we would like to first check the assumptions of our models hold, namely that multicollinearity is minimal. We do this in the cell below by computing the variance inflation factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad6c7e-2481-49cd-abf8-61ed3c0df07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_variables_vif <- \n",
    "   vif(lm(Metacritic ~ReleaseDate+RecommendationCount+IsFree+GenreIsIndie+GenreIsAction+GenreIsAdventure+GenreIsCasual+GenreIsStrategy+GenreIsRPG+GenreIsSimulation+GenreIsEarlyAccess+GenreIsSports+\n",
    "GenreIsRacing+GenreIsMassivelyMultiplayer+PriceInitial,data=training_Steam))\n",
    "\n",
    "lasso_variables_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d2275c-2dbd-49fc-96b7-4beba824861f",
   "metadata": {},
   "source": [
    "All of the input variables have a variance inflation factor (VIF) of between 1 - 1.5. Because the VIF is not very high, we are reasonably confident that multicollinearity will not be a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8845b23-1999-4ec3-891e-e58dbd315560",
   "metadata": {},
   "source": [
    "Now, let's compute an additive linear regression model using all of the variables. This will help us understand which variables are statistically significant, and which variables are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d42022-7de0-4f0d-8ae5-cbda971eadd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games_mlr_add <- lm(Metacritic ~ ., data = training_Steam %>% select(-ResponseName)) #use training steam as the data, but omit ResponseName\n",
    "\n",
    "steam_games_mlr_add_tidy <- tidy(steam_games_mlr_add, conf.level = 0.9, conf.int = TRUE) %>% mutate_if(is.numeric, round, 2) #show estimates and intervals\n",
    "steam_games_mlr_add_tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c951f8c-87c5-465c-9c80-04ef94c8b809",
   "metadata": {},
   "source": [
    "**Figure 6. Estimated Coefficients of an Additive Multiple Linear Regression Model**\n",
    "\n",
    "Below we will compute the p-value of this model to ensure that it is better than an intercept-only model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bcf471-e1d9-4759-923c-ba21eea91b72",
   "metadata": {},
   "source": [
    "With this full addictive model, let's further check the assumption of normality and whether heteroscedasticity exsits in the dataset which means the errors do not have equal variance, we will diagose graphically by checking the QQ plot and comparing the fitted values to the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27cd069-5abc-402a-b4c1-4bca6f9d4e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(steam_games_mlr_add,1:2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e1873-71f3-44f9-8448-b8ec0f00f22d",
   "metadata": {},
   "source": [
    "Ignoring some outliers the data seems to be approximately normal and homoscedastic, also by the CLT that our sample size is large enough, so we can assume the distribution is normal, and the error term is also normally distributed. Therefore, we have checked that the model assumptions are met for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c9f97-4eac-4d8a-9794-1a9749857112",
   "metadata": {},
   "outputs": [],
   "source": [
    "glance(steam_games_mlr_add)$p.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be2c16a-873e-4b1e-b76c-34085a7d71bf",
   "metadata": {},
   "source": [
    "The full model above may not be the best, as there might be some variables that might not help with prediction.\n",
    "Let's try using an automated proceedure to select the variables.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c66215-4912-4410-b14d-22813ecf13a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_forward_sel<- regsubsets(\n",
    "    x = Metacritic ~., nvmax=15,\n",
    "    data=training_Steam[,-1],\n",
    "    method=\"forward\",\n",
    "    )\n",
    "steam_forward_summary<-summary(steam_forward_sel) \n",
    "steam_forward_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f71b8d-8637-4efe-9460-1d1f51e30c58",
   "metadata": {},
   "source": [
    "We are going to select the best one in terms of its goodness of fit from the 15 possible models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b68993-efa8-47ad-a4d8-1ad925755f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_forward_summary_df<-tibble(\n",
    "n_input_variables = 1:15,\n",
    "RSQ = steam_forward_summary$rsq,\n",
    "RSS = steam_forward_summary$rss,\n",
    "ADJ.R2 = steam_forward_summary$adjr2,\n",
    "Cp = steam_forward_summary$cp,\n",
    "BIC = steam_forward_summary$bic\n",
    "    )\n",
    "steam_forward_summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd205f4e-cd99-46ef-9521-1f8d83ca14f9",
   "metadata": {},
   "source": [
    "For the purpose of create a \"best\" predictive model we will looking for the smallest Cp value. Thus, we select the predictive model with 8 variables.\n",
    "\n",
    "The variables we selected are:\n",
    "1. \"ReleaseDate\" 2. \"RecommendationCount\" 3. \"GenreIsAction\" 4. \"GenreIsRPG\" 5. \"GenreIsSimulation\" \n",
    "6. \"GenreIsEarlyAccess\" 7. \"GenreIsMassivelyMultiplayer\" 8.\"PriceInitial\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e026c111-36ad-4ea3-93a8-c8875a71e575",
   "metadata": {},
   "source": [
    "Let's train the selected models and use it to predict in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794edc05-2779-4786-bdb6-2ddbbfa58bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games_mlr_red <- lm(Metacritic ~ ReleaseDate+RecommendationCount+GenreIsAction+\n",
    "                          GenreIsRPG+GenreIsSimulation+GenreIsEarlyAccess+\n",
    "                          GenreIsMassivelyMultiplayer+PriceInitial, \n",
    "    data = training_Steam %>% select(-ResponseName)) #To estimeate we use training steam as the data, but omit ResponseName\n",
    "\n",
    "steam_games_pred_red <- predict(steam_games_mlr_red, newdata = testing_Steam)\n",
    "head(steam_games_pred_red) #predict on test set\n",
    "\n",
    "steam_games_R_MSE_models <- tibble(\n",
    "Model = \"OLS Reduced Regression\",\n",
    "R_MSE = rmse(\n",
    "preds = steam_games_pred_red,\n",
    "actuals = testing_Steam$Metacritic\n",
    ")\n",
    ")\n",
    "\n",
    "steam_games_R_MSE_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d440f3-17fb-4e13-a181-1144e0ea0e1f",
   "metadata": {},
   "source": [
    "## Lasso \n",
    "\n",
    "Since the above LR assumes a linear relationship and might not be the best way to find the predictors for the response variable.\n",
    "We would like to also compare the Lasso penalized penalized method to select the variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3616252-c474-459b-a126-c32e8e5e0eae",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To continue with LASSO selection, will build a matrix and vector with the data so it can be properly used by the `glmnet` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881bb267-f47b-4d19-8233-8af39791a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head(training_Steam)\n",
    "# nrow(training_Steam)\n",
    "#head(testing_Steam)\n",
    "# nrow(testing_Steam)\n",
    "Steam_X_test <- testing_Steam %>% select(-\"Metacritic\",-\"ResponseName\")  %>% data.matrix()\n",
    "Steam_Y_test <- unlist(testing_Steam[, \"Metacritic\"])%>%as.numeric()\n",
    "# Build matrix and vector required by `glmnet`\n",
    "\n",
    "Steam_X_train <- model.matrix(Metacritic ~ . -ResponseName,\n",
    "  data = training_Steam)[, -1] #remove index\n",
    "\n",
    "Steam_Y_train <- unlist(training_Steam[, \"Metacritic\"])%>%as.numeric()\n",
    "\n",
    "head(Steam_X_train) \n",
    "head(Steam_Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea558395-b1a1-4ba0-96b0-6e786610cdf6",
   "metadata": {},
   "source": [
    "We will now select the value of  𝜆  that provides the smallest  MSE test  using cross-validation. Finally, we will fit the model using this lambda value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8a57f-c88c-4fb4-a654-824d698129a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Steam_cv_lambda_LASSO <- cv.glmnet(\n",
    "  x = Steam_X_train, y = Steam_Y_train,\n",
    "  alpha = 1)\n",
    "\n",
    "\n",
    "Steam_lambda_min_MSE <- round(Steam_cv_lambda_LASSO$lambda.min, 4)\n",
    "Steam_lambda_min_MSE\n",
    "\n",
    "options(repr.plot.height = 8, repr.plot.width = 10)\n",
    "par(mar = c(5, 4.1, 7, 2.1))\n",
    "plot(Steam_cv_lambda_LASSO)\n",
    "title(main = 'LASSO Lambda Selection, cross validation', cex.main = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b181b7-5db2-4a7a-b668-b5cc9323c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Lasso regression with selected lamda\n",
    "LASSO_min_add <- glmnet(\n",
    "  x = Steam_X_train, y = Steam_Y_train,\n",
    "  alpha = 1,\n",
    "  lambda = Steam_lambda_min_MSE\n",
    ")\n",
    "\n",
    "coef(LASSO_min_add)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8bb95d-6164-4d4d-b0da-ebbbbaf56abf",
   "metadata": {},
   "source": [
    "Unfortunately, it looks like LASSO selected against using all of the variables, and chose to use only the intercept. This is a problem of Lasso penalized method dealing with categorial variables, so the an unusual result given that our full linear regression model was statistically better than the intercept-only model. However, it appears that although the p-value was small, these variables were still not all that relevant in predicting the `Metacritic` score (perhaps because of a low effect-size). \n",
    "\n",
    "Now, we will use the trained model to predict the Metacritic score in the test set. For comparison, we will also compute the rmse of our full additive linear regression model and combine them with the foward selected reduced model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c36c3d-969a-4a3f-9b40-abbf6fc635f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Steam_test_pred_LASSO <- predict(LASSO_min_add,\n",
    "  newx =Steam_X_test)\n",
    "\n",
    "rmse_stats <- tibble(\n",
    "    Model = \"LASSO Regression with minimum MSE\",\n",
    "    R_MSE = rmse(\n",
    "      preds = Steam_test_pred_LASSO,\n",
    "      actuals = testing_Steam$Metacritic\n",
    "    )\n",
    "  )\n",
    "\n",
    "testing_Steam_lm_format <- testing_Steam %>% select(-Metacritic, -ResponseName)\n",
    "\n",
    "Steam_test_pred_full_mlr <- predict(steam_games_mlr_add,\n",
    "  newdata = testing_Steam_lm_format)\n",
    "\n",
    "\n",
    "rbind(rmse_stats,steam_games_R_MSE_models,\n",
    "      tibble(Model = \"Full Additive Linear Regression (No penalization or selection)\",\n",
    "            R_MSE = rmse(\n",
    "                preds = Steam_test_pred_full_mlr,\n",
    "                actuals = testing_Steam$Metacritic\n",
    "            )\n",
    "            )\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed909bd5-b256-4450-a02d-dbcfc1acd22c",
   "metadata": {},
   "source": [
    "**Figure 7. RMSE of LASSO selected model and Full Additive Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5be80ea-e004-4e43-bb85-009be9ca3b32",
   "metadata": {},
   "source": [
    "RMSE measures is generally a measure of error between our predicted values and the actual values. A lower RMSE is better. In this case, these results imply that the square root of the average of the square residuals is around 11 for three of our models. In this case, the reduced linear regression model selected by forward selection performed slightly better, but these results may be down to chance and the particular split of the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586c59a3-9565-47d2-a1c1-0b4c38735eca",
   "metadata": {},
   "source": [
    "\n",
    "### Methods (Maybe we change this to discussion)\n",
    "\n",
    "This report uses a dataset with huge sample of 12624 games and 19 variables. Once filtered to remove observations with missing values, the sample size became more reasonable, at around 2000. \n",
    "\n",
    "Wrangling was done to make variables easier to use in our model. The `ReleaseDate` variable was converted from a character format to a continuous variable. All of the logical variables representing a game's genre or category were converted to a factor so that our models could use them. \n",
    "\n",
    "The report uses scatterplots and tables to visualize and summarize the data and the relationships between variables. It also fits an additive multiple linear regression model using all of the variables in the dataset. However, more must be done in the final report. In particular, we will need to employ model selection techniques to answer our inferential questions and figure out which variables are relevant. To answer our predictive questions we will also need to evaluate our models using metrics such the **MSE** (Mean Squared Error). \n",
    "\n",
    "\n",
    "If we are able to successfully create a predictive model for Metacritic scores, consumers could use this model to easily make a decision about their gaming purchase based on some input variables. Additionally, statistical analysis of this dataset will allow us to understand the relationship between Metacritic scores and other properties of a game. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a801cdd5-0614-4a23-a378-86069068d0fc",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "\n",
    "Greenwood-Ericksen, A., Poorman, S. R., &amp; Papp, R. (2013). On the validity of Metacritic in assessing game value. *Eludamos: Journal for Computer Game Culture, 7*(1), 101–127. https://doi.org/10.7557/23.6150 \n",
    "\n",
    "Johnson, D., Watling, C., Gardner, J., &amp; Nacke, L. E. (2014). The edge of glory: the relationship between metacritic scores and player experience. *Proceedings of the First ACM SIGCHI Annual Symposium on Computer-Human Interaction in Play*. https://doi.org/10.1145/2658537.2658694 \n",
    "\n",
    "*Steam games*. Kaggle. (2022, October 21). Retrieved November 9, 2022, from https://www.kaggle.com/datasets/thedevastator/get-your-game-on-metacritic-recommendations-and \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ee6d8-b673-4c90-9228-dd0e30e437fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4165b7b-ddba-4e3e-814e-43d7a4703958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc21c0-11bf-4455-8d6c-1d37514ab0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce44b3-e4a0-4419-b437-5528c401f0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f5ba86-88f6-4452-8a20-a62d9d561dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
